{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks for MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading MNIST\n",
    "Here we load the dataset and create data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.MNIST('../data', train=True, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "test_ds = datasets.MNIST('../data', train=False, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "#batch_size = 5 # for testing\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1155f00b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dl = iter(train_loader)\n",
    "x, y = next(train_dl)\n",
    "\n",
    "def show(img, title=None):\n",
    "    plt.imshow(img, interpolation='none', cmap=\"gray\")\n",
    "    if title is not None: plt.title(title)\n",
    "        \n",
    "# first from torch to numpy\n",
    "X = x.numpy(); Y = y.numpy()\n",
    "X.shape\n",
    "\n",
    "show(X[0][0], Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(M = 300):\n",
    "    net = nn.Sequential(nn.Linear(28*28, M),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(M, 10))\n",
    "    return net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(train_loader, test_loader, num_epochs, model, optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            batch = images.shape[0] # size of the batch\n",
    "            # Convert torch tensor to Variable, change shape of the input\n",
    "            images = Variable(images.view(-1, 28*28)).cuda()\n",
    "            labels = Variable(labels).cuda()\n",
    "        \n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()  # zero the gradient buffer\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            total += batch\n",
    "            sum_loss += batch * loss.data[0]\n",
    "        train_loss = sum_loss/total\n",
    "        val_acc, val_loss = model_accuracy_loss(model, test_loader)\n",
    "        \n",
    "    return val_acc, val_loss, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_accuracy_loss(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    sum_loss = 0.0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = Variable(images.view(-1, 28*28)).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        outputs = model(images)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        sum_loss += labels.size(0)*loss.data[0]\n",
    "        total += labels.size(0)\n",
    "        correct += pred.eq(labels.data).cpu().sum()\n",
    "    return 100 * correct / total, sum_loss/ total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "## 1: Explore learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train_lr(lr):\n",
    "    net = get_model()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, \n",
    "                                                 num_epochs=10, model=net, optimizer=optimizer)\n",
    "    return val_acc, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr_grid = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "lval_acc = []\n",
    "lval_loss = []\n",
    "for lr in lr_grid:\n",
    "    val_acc, val_loss = train_lr(lr)\n",
    "    lval_acc.append(val_acc)\n",
    "    lval_loss.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = [('Learning_rate', lr_grid),('Val_acc', lval_acc),('Val_loss', lval_loss)]\n",
    "df = pd.DataFrame.from_items(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning_rate</th>\n",
       "      <th>Val_acc</th>\n",
       "      <th>Val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>97.92</td>\n",
       "      <td>0.085189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>97.73</td>\n",
       "      <td>0.078762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>95.44</td>\n",
       "      <td>0.274616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>92.84</td>\n",
       "      <td>0.255678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>11.99</td>\n",
       "      <td>2.279965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>10.40</td>\n",
       "      <td>2.400137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning_rate  Val_acc  Val_loss\n",
       "3        0.00100    97.92  0.085189\n",
       "4        0.00010    97.73  0.078762\n",
       "2        0.01000    95.44  0.274616\n",
       "5        0.00001    92.84  0.255678\n",
       "1        0.10000    11.99  2.279965\n",
       "0        1.00000    10.40  2.400137"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\"Val_acc\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best two learning rate values are 0.0001 and 0.001. \n",
    "To further explore, we will look at the values between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning_rate</th>\n",
       "      <th>Val_acc</th>\n",
       "      <th>Val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>98.08</td>\n",
       "      <td>0.068757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>98.02</td>\n",
       "      <td>0.083041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>97.81</td>\n",
       "      <td>0.069932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0006</td>\n",
       "      <td>97.76</td>\n",
       "      <td>0.088492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning_rate  Val_acc  Val_loss\n",
       "1         0.0004    98.08  0.068757\n",
       "3         0.0008    98.02  0.083041\n",
       "0         0.0002    97.81  0.069932\n",
       "2         0.0006    97.76  0.088492"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_grid2 = np.arange(0.0002,0.001,0.0002)\n",
    "lval_acc = []\n",
    "lval_loss = []\n",
    "for lr in lr_grid2:\n",
    "    val_acc, val_loss = train_lr(lr)\n",
    "    lval_acc.append(val_acc)\n",
    "    lval_loss.append(val_loss)\n",
    "\n",
    "data = [('Learning_rate', lr_grid2),('Val_acc', lval_acc),('Val_loss', lval_loss)]\n",
    "\n",
    "df = pd.DataFrame.from_items(data)\n",
    "df.sort_values(\"Val_acc\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that a learning rate of 0.0004 can achieve even better validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Explore the size of hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train_M(m):\n",
    "    net = get_model(m)\n",
    "    learning_rate = 0.01\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, \n",
    "                                                 num_epochs=10, model=net, optimizer=optimizer)\n",
    "    return train_loss, val_acc, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size 10.000000 - train loss: 0.3359; validation loss: 0.3647; validation accuracy: 90.2600\n",
      "Hidden Layer Size 50.000000 - train loss: 0.1746; validation loss: 0.2239; validation accuracy: 94.5900\n",
      "Hidden Layer Size 100.000000 - train loss: 0.1520; validation loss: 0.2632; validation accuracy: 95.2700\n",
      "Hidden Layer Size 300.000000 - train loss: 0.1537; validation loss: 0.2236; validation accuracy: 96.0600\n",
      "Hidden Layer Size 1000.000000 - train loss: 0.1519; validation loss: 0.2610; validation accuracy: 95.2900\n",
      "Hidden Layer Size 2000.000000 - train loss: 0.1534; validation loss: 0.2781; validation accuracy: 95.1300\n"
     ]
    }
   ],
   "source": [
    "m_grid = [10, 50, 100, 300, 1000, 2000]\n",
    "lval_acc = []\n",
    "lval_loss = []\n",
    "for m in m_grid:\n",
    "    train_loss,val_acc, val_loss = train_M(m)\n",
    "    lval_acc.append(val_acc)\n",
    "    lval_loss.append(val_loss)\n",
    "    print (\"Hidden Layer Size %f - train loss: %.4f; validation loss: %.4f; validation accuracy: %.4f\" %(m, train_loss, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = [('Hidden Layer Size', m_grid),('Val_acc', lval_acc),('Val_loss', lval_loss)]\n",
    "df = pd.DataFrame.from_items(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layer Size</th>\n",
       "      <th>Val_acc</th>\n",
       "      <th>Val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>96.06</td>\n",
       "      <td>0.223615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>95.29</td>\n",
       "      <td>0.260989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>95.27</td>\n",
       "      <td>0.263172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>95.13</td>\n",
       "      <td>0.278084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>94.59</td>\n",
       "      <td>0.223851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>90.26</td>\n",
       "      <td>0.364705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hidden Layer Size  Val_acc  Val_loss\n",
       "3                300    96.06  0.223615\n",
       "4               1000    95.29  0.260989\n",
       "2                100    95.27  0.263172\n",
       "5               2000    95.13  0.278084\n",
       "1                 50    94.59  0.223851\n",
       "0                 10    90.26  0.364705"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\"Val_acc\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the experiment, a hidden layer size of 300 achieves the best performance - with highest validation accuracy and lowest validation loss.  \n",
    "The model with hidden layer size of 2000 is overfitting. Even though the train loss of this model is lower than model with hidden layer size 300, but its performance on the validation set is worse. Therefore, we can tell that it is overfitting the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore weight decay parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_wd(weight):\n",
    "    net = get_model()\n",
    "    learning_rate = 0.001\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay = weight)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, \n",
    "                                                 num_epochs=20, model=net, optimizer=optimizer)\n",
    "    return val_acc, val_loss, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight decay parameter 0.000000 - train loss: 0.0105; validation loss: 0.1306; validation accuracy: 97.6500\n",
      "Weight decay parameter 0.000100 - train loss: 0.0165; validation loss: 0.0847; validation accuracy: 97.9500\n",
      "Weight decay parameter 0.001000 - train loss: 0.0512; validation loss: 0.0734; validation accuracy: 97.6400\n",
      "Weight decay parameter 0.010000 - train loss: 0.1558; validation loss: 0.1525; validation accuracy: 95.9700\n",
      "Weight decay parameter 0.100000 - train loss: 0.4622; validation loss: 0.4395; validation accuracy: 89.6700\n",
      "Weight decay parameter 0.300000 - train loss: 0.8108; validation loss: 0.7853; validation accuracy: 86.2200\n"
     ]
    }
   ],
   "source": [
    "weight_grid = [0, 0.0001, 0.001, 0.01, 0.1, 0.3]\n",
    "ltr_loss = []\n",
    "lval_acc = []\n",
    "lval_loss = []\n",
    "for weight in weight_grid:\n",
    "    val_acc, val_loss, train_loss = train_wd(weight)\n",
    "    ltr_loss.append(train_loss)\n",
    "    lval_acc.append(val_acc)\n",
    "    lval_loss.append(val_loss)\n",
    "    print (\"Weight decay parameter %f - train loss: %.4f; validation loss: %.4f; validation accuracy: %.4f\" %(weight, train_loss, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight decay</th>\n",
       "      <th>Val_acc</th>\n",
       "      <th>Val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>97.95</td>\n",
       "      <td>0.084719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>97.65</td>\n",
       "      <td>0.130628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>97.64</td>\n",
       "      <td>0.073435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>95.97</td>\n",
       "      <td>0.152475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>89.67</td>\n",
       "      <td>0.439503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.785284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight decay  Val_acc  Val_loss\n",
       "1        0.0001    97.95  0.084719\n",
       "0        0.0000    97.65  0.130628\n",
       "2        0.0010    97.64  0.073435\n",
       "3        0.0100    95.97  0.152475\n",
       "4        0.1000    89.67  0.439503\n",
       "5        0.3000    86.22  0.785284"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [('Weight decay', weight_grid),('Val_acc', lval_acc),('Val_loss', lval_loss)]\n",
    "df = pd.DataFrame.from_items(data)\n",
    "df.sort_values(\"Val_acc\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a weight decay parameter of 0.0001, the model achieved the best validation accuracy. The validation loss is also lower than model without weight decay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Explore dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_v2(M = 300, p=0):\n",
    "    modules = []\n",
    "    modules.append(nn.Linear(28*28, M))\n",
    "    modules.append(nn.ReLU())\n",
    "    if p > 0:\n",
    "        modules.append(nn.Dropout(p))\n",
    "    modules.append(nn.Linear(M, 10))\n",
    "    return nn.Sequential(*modules).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_drop(p):\n",
    "    net2 = get_model_v2(M = 300, p=p)\n",
    "    learning_rate = 0.001\n",
    "    optimizer = optim.Adam(net2.parameters(), lr=learning_rate)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, \n",
    "                                                 num_epochs=20, model=net2, optimizer=optimizer)\n",
    "    return val_acc, val_loss, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop out 0.000000 - train loss: 0.0111; validation loss: 0.1205; validation accuracy: 97.9600\n",
      "Drop out 0.200000 - train loss: 0.0212; validation loss: 0.0901; validation accuracy: 98.1400\n",
      "Drop out 0.400000 - train loss: 0.0454; validation loss: 0.0873; validation accuracy: 98.1000\n",
      "Drop out 0.600000 - train loss: 0.0943; validation loss: 0.0824; validation accuracy: 97.9900\n",
      "Drop out 0.800000 - train loss: 0.2295; validation loss: 0.1022; validation accuracy: 97.4000\n",
      "Drop out 1.000000 - train loss: 2.3013; validation loss: 2.2965; validation accuracy: 10.4000\n"
     ]
    }
   ],
   "source": [
    "p_grid = np.arange(0,1.05,0.2)\n",
    "ltr_loss = []\n",
    "lval_acc = []\n",
    "lval_loss = []\n",
    "for p in p_grid:\n",
    "    val_acc, val_loss, train_loss = train_drop(p)\n",
    "    ltr_loss.append(train_loss)\n",
    "    lval_acc.append(val_acc)\n",
    "    lval_loss.append(val_loss)\n",
    "    print (\"Drop out %f - train loss: %.4f; validation loss: %.4f; validation accuracy: %.4f\" %(p, train_loss, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drop out parameter</th>\n",
       "      <th>Val_acc</th>\n",
       "      <th>Val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>98.14</td>\n",
       "      <td>0.090087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>98.10</td>\n",
       "      <td>0.087302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>97.99</td>\n",
       "      <td>0.082423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>97.96</td>\n",
       "      <td>0.120459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>97.40</td>\n",
       "      <td>0.102174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.40</td>\n",
       "      <td>2.296452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Drop out parameter  Val_acc  Val_loss\n",
       "1                 0.2    98.14  0.090087\n",
       "2                 0.4    98.10  0.087302\n",
       "3                 0.6    97.99  0.082423\n",
       "0                 0.0    97.96  0.120459\n",
       "4                 0.8    97.40  0.102174\n",
       "5                 1.0    10.40  2.296452"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [('Drop out parameter', p_grid),('Val_acc', lval_acc),('Val_loss', lval_loss)]\n",
    "df = pd.DataFrame.from_items(data)\n",
    "df.sort_values(\"Val_acc\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with dropout rate of 0.2 achieves the best validation accuracy. Models with dropout parameter 0.2,0.4 and 0.6 all perform better than model without dropout.   \n",
    "I believe the reason model with proper dropout rate performs better is that by randomly dropping out a proportion of neurons, it reduced the dependencies between neurons, and force each neuron to learn some more robust features of the data. This will help prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower the learning rate after 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model2(train_loader, test_loader, num_epochs, model, optimizer):\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0.0\n",
    "        scheduler.step()\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            batch = images.shape[0] # size of the batch\n",
    "            # Convert torch tensor to Variable, change shape of the input\n",
    "            images = Variable(images.view(-1, 28*28)).cuda()\n",
    "            labels = Variable(labels).cuda()\n",
    "        \n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()  # zero the gradient buffer\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            total += batch\n",
    "            sum_loss += batch * loss.data[0]\n",
    "        train_loss = sum_loss/total\n",
    "        #print('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, train_loss))\n",
    "        \n",
    "        val_acc, val_loss = model_accuracy_loss(model, test_loader)\n",
    "        #print('Epoch [%d/%d], Valid Accuracy: %.4f, Valid Loss: %.4f' %(epoch+1, num_epochs, val_acc, val_loss))\n",
    "    return val_acc, val_loss, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with dropout and changing learning rate to 0.0005 after 10 epochs\n",
    "def train_drop_vlr(p):\n",
    "    net2 = get_model_v2(M = 300, p=p)\n",
    "    optimizer = optim.Adam(net2.parameters(), lr=0.001)\n",
    "    val_acc, val_loss, train_loss = train_model2(train_loader, test_loader, \n",
    "                                                 num_epochs=20, model=net2, optimizer=optimizer)\n",
    "    return val_acc, val_loss, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop out 0.000000 - train loss: 0.0016; validation loss: 0.1035; validation accuracy: 98.0600\n",
      "Drop out 0.200000 - train loss: 0.0105; validation loss: 0.0780; validation accuracy: 98.2300\n",
      "Drop out 0.400000 - train loss: 0.0247; validation loss: 0.0696; validation accuracy: 98.4200\n",
      "Drop out 0.600000 - train loss: 0.0644; validation loss: 0.0690; validation accuracy: 98.2200\n",
      "Drop out 0.800000 - train loss: 0.1809; validation loss: 0.0984; validation accuracy: 97.4000\n",
      "Drop out 1.000000 - train loss: 2.3012; validation loss: 2.3679; validation accuracy: 9.2600\n"
     ]
    }
   ],
   "source": [
    "p_grid = np.arange(0,1.05,0.2)\n",
    "ltr_loss = []\n",
    "lval_acc = []\n",
    "lval_loss = []\n",
    "for p in p_grid:\n",
    "    val_acc, val_loss, train_loss = train_drop_vlr(p)\n",
    "    ltr_loss.append(train_loss)\n",
    "    lval_acc.append(val_acc)\n",
    "    lval_loss.append(val_loss)\n",
    "    print (\"Drop out %f - train loss: %.4f; validation loss: %.4f; validation accuracy: %.4f\" %(p, train_loss, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drop out parameter</th>\n",
       "      <th>Val_acc</th>\n",
       "      <th>Val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>98.42</td>\n",
       "      <td>0.069558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>98.23</td>\n",
       "      <td>0.077973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>98.22</td>\n",
       "      <td>0.069014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.06</td>\n",
       "      <td>0.103526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8</td>\n",
       "      <td>97.40</td>\n",
       "      <td>0.098389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.26</td>\n",
       "      <td>2.367884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Drop out parameter  Val_acc  Val_loss\n",
       "2                 0.4    98.42  0.069558\n",
       "1                 0.2    98.23  0.077973\n",
       "3                 0.6    98.22  0.069014\n",
       "0                 0.0    98.06  0.103526\n",
       "4                 0.8    97.40  0.098389\n",
       "5                 1.0     9.26  2.367884"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [('Drop out parameter', p_grid),('Val_acc', lval_acc),('Val_loss', lval_loss)]\n",
    "df = pd.DataFrame.from_items(data)\n",
    "df.sort_values(\"Val_acc\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the results with the last experiment (with constant learning rate), reducing the learning rate after 10 epochs helps the model achieve better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-layer NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started with a base model with 2 hidden layer, 1st hidden layer size is 300, 2nd hidden layer size is 100. Both hidden layer use ReLU as activation fuction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_v3(M1 = 300, M2 = 100):\n",
    "    net = nn.Sequential(nn.Linear(28*28, M1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(M1, M2),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(M2, 10))\n",
    "    return net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(train_loader, test_loader, num_epochs, model, optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            batch = images.shape[0] # size of the batch\n",
    "            # Convert torch tensor to Variable, change shape of the input\n",
    "            images = Variable(images.view(-1, 28*28)).cuda()\n",
    "            labels = Variable(labels).cuda()\n",
    "        \n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()  # zero the gradient buffer\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            total += batch\n",
    "            sum_loss += batch * loss.data[0]\n",
    "        train_loss = sum_loss/total\n",
    "        #print('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, train_loss))\n",
    "        \n",
    "        val_acc, val_loss = model_accuracy_loss(model, test_loader)\n",
    "        #print('Epoch [%d/%d], Valid Accuracy: %.4f, Valid Loss: %.4f' %(epoch+1, num_epochs, val_acc, val_loss))\n",
    "        \n",
    "    return val_acc, val_loss, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Valid Accuracy: 95.3000, Valid Loss: 0.1529\n",
      "Epoch [2/20], Valid Accuracy: 97.0800, Valid Loss: 0.1016\n",
      "Epoch [3/20], Valid Accuracy: 97.5000, Valid Loss: 0.0824\n",
      "Epoch [4/20], Valid Accuracy: 97.3100, Valid Loss: 0.0820\n",
      "Epoch [5/20], Valid Accuracy: 97.3400, Valid Loss: 0.0856\n",
      "Epoch [6/20], Valid Accuracy: 97.5500, Valid Loss: 0.0835\n",
      "Epoch [7/20], Valid Accuracy: 97.9600, Valid Loss: 0.0640\n",
      "Epoch [8/20], Valid Accuracy: 97.7500, Valid Loss: 0.0728\n",
      "Epoch [9/20], Valid Accuracy: 97.9500, Valid Loss: 0.0669\n",
      "Epoch [10/20], Valid Accuracy: 97.9900, Valid Loss: 0.0619\n",
      "Epoch [11/20], Valid Accuracy: 97.9000, Valid Loss: 0.0646\n",
      "Epoch [12/20], Valid Accuracy: 97.9400, Valid Loss: 0.0654\n",
      "Epoch [13/20], Valid Accuracy: 97.9400, Valid Loss: 0.0657\n",
      "Epoch [14/20], Valid Accuracy: 98.0700, Valid Loss: 0.0602\n",
      "Epoch [15/20], Valid Accuracy: 97.6000, Valid Loss: 0.0784\n",
      "Epoch [16/20], Valid Accuracy: 98.0900, Valid Loss: 0.0653\n",
      "Epoch [17/20], Valid Accuracy: 97.9800, Valid Loss: 0.0649\n",
      "Epoch [18/20], Valid Accuracy: 97.7600, Valid Loss: 0.0684\n",
      "Epoch [19/20], Valid Accuracy: 97.9500, Valid Loss: 0.0702\n",
      "Epoch [20/20], Valid Accuracy: 97.9100, Valid Loss: 0.0650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(97.91, 0.06501228814125061, 0.03060062550107638)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = get_model_v3()\n",
    "learning_rate = 0.0005\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay = 0.001)\n",
    "train_model(train_loader, test_loader, num_epochs=20, model=net, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that without tunning, the 3-layer-NN outperforms a base 2-layer model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the size of second Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_M(m2):\n",
    "    net = get_model_v3(M2=m2)\n",
    "    learning_rate = 0.0005\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, \n",
    "                                                 num_epochs=10, model=net, optimizer=optimizer)\n",
    "    return train_loss, val_acc, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd Hidden Layer Size 10.000000 - train loss: 0.0185; validation loss: 0.0692; validation accuracy: 98.1000\n",
      "2nd Hidden Layer Size 50.000000 - train loss: 0.0147; validation loss: 0.0739; validation accuracy: 97.8300\n",
      "2nd Hidden Layer Size 100.000000 - train loss: 0.0138; validation loss: 0.0807; validation accuracy: 97.8700\n",
      "2nd Hidden Layer Size 150.000000 - train loss: 0.0158; validation loss: 0.0828; validation accuracy: 98.0000\n",
      "2nd Hidden Layer Size 200.000000 - train loss: 0.0136; validation loss: 0.0756; validation accuracy: 97.9900\n",
      "2nd Hidden Layer Size 300.000000 - train loss: 0.0139; validation loss: 0.0813; validation accuracy: 98.0800\n"
     ]
    }
   ],
   "source": [
    "m2_grid = [10, 50, 100, 150, 200, 300]\n",
    "ltr_loss = []\n",
    "lval_acc = []\n",
    "lval_loss = []\n",
    "for m2 in m2_grid:\n",
    "    train_loss,val_acc, val_loss = train_M(m2)\n",
    "    ltr_loss.append(train_loss)\n",
    "    lval_acc.append(val_acc)\n",
    "    lval_loss.append(val_loss)\n",
    "    print (\"2nd Hidden Layer Size %f - train loss: %.4f; validation loss: %.4f; validation accuracy: %.4f\" %(m2, train_loss, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2nd Hidden Layer Size</th>\n",
       "      <th>Val_acc</th>\n",
       "      <th>Val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>98.10</td>\n",
       "      <td>0.069212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>300</td>\n",
       "      <td>98.08</td>\n",
       "      <td>0.081285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>98.00</td>\n",
       "      <td>0.082839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>97.99</td>\n",
       "      <td>0.075645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>97.87</td>\n",
       "      <td>0.080712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>97.83</td>\n",
       "      <td>0.073857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2nd Hidden Layer Size  Val_acc  Val_loss\n",
       "0                     10    98.10  0.069212\n",
       "5                    300    98.08  0.081285\n",
       "3                    150    98.00  0.082839\n",
       "4                    200    97.99  0.075645\n",
       "2                    100    97.87  0.080712\n",
       "1                     50    97.83  0.073857"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [('2nd Hidden Layer Size', m2_grid),('Val_acc', lval_acc),('Val_loss', lval_loss)]\n",
    "df = pd.DataFrame.from_items(data)\n",
    "df.sort_values(\"Val_acc\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this experiment, I found that a second hidden layer of size 10 actually outperform others with larger sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out different values of weight deday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_wd(weight):\n",
    "    net = get_model_v3()\n",
    "    learning_rate = 0.0005\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay = weight)\n",
    "    val_acc, val_loss, train_loss = train_model(train_loader, test_loader, \n",
    "                                                 num_epochs=20, model=net, optimizer=optimizer)\n",
    "    return val_acc, val_loss, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight decay parameter 0.000100 - train loss: 0.0121; validation loss: 0.0714; validation accuracy: 98.2400\n",
      "Weight decay parameter 0.000500 - train loss: 0.0207; validation loss: 0.0793; validation accuracy: 97.6600\n",
      "Weight decay parameter 0.001000 - train loss: 0.0308; validation loss: 0.0600; validation accuracy: 98.0600\n",
      "Weight decay parameter 0.005000 - train loss: 0.0886; validation loss: 0.1004; validation accuracy: 97.1900\n",
      "Weight decay parameter 0.010000 - train loss: 0.1339; validation loss: 0.1305; validation accuracy: 96.5700\n"
     ]
    }
   ],
   "source": [
    "weight_grid = [0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
    "ltr_loss = []\n",
    "lval_acc = []\n",
    "lval_loss = []\n",
    "for weight in weight_grid:\n",
    "    val_acc, val_loss, train_loss = train_wd(weight)\n",
    "    ltr_loss.append(train_loss)\n",
    "    lval_acc.append(val_acc)\n",
    "    lval_loss.append(val_loss)\n",
    "    print (\"Weight decay parameter %f - train loss: %.4f; validation loss: %.4f; validation accuracy: %.4f\" %(weight, train_loss, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight decay</th>\n",
       "      <th>Val_acc</th>\n",
       "      <th>Val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>98.24</td>\n",
       "      <td>0.071434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>98.06</td>\n",
       "      <td>0.060015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>97.66</td>\n",
       "      <td>0.079251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>97.19</td>\n",
       "      <td>0.100447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>96.57</td>\n",
       "      <td>0.130469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight decay  Val_acc  Val_loss\n",
       "0        0.0001    98.24  0.071434\n",
       "2        0.0010    98.06  0.060015\n",
       "1        0.0005    97.66  0.079251\n",
       "3        0.0050    97.19  0.100447\n",
       "4        0.0100    96.57  0.130469"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [('Weight decay', weight_grid),('Val_acc', lval_acc),('Val_loss', lval_loss)]\n",
    "df = pd.DataFrame.from_items(data)\n",
    "df.sort_values(\"Val_acc\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From the two layer NN, I found that weight decay value 0.0001 and 0.001 performs well. So I tested a few values between 0.0001 and 0.01. It turns out that weight decay factor of 0.0001 also performs the best for 3 layer NN.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
