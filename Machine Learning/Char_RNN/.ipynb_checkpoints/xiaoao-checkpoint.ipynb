{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Char-rnn training on Chinese Novel -笑傲江湖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f= 'data/xiaoaojianghu_jinyong.txt'\n",
    "file = open(f, encoding='utf-16').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_len = len(file)\n",
    "n_characters = len(set(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_lookup_tables(file):\n",
    "    vocab = set(file)\n",
    "    vocab_to_int = {word: idx for idx, word in enumerate(vocab)}\n",
    "    int_to_vocab = dict(enumerate(vocab))\n",
    "    return vocab_to_int, int_to_vocab\n",
    "\n",
    "vocab_to_int, int_to_vocab = create_lookup_tables(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "他身子变成四块之后，还能不能将桃谷六仙像捏蚂蚁般捏死。\n",
      "令狐冲为凑桃谷六仙之兴，强提精神，和他们谈笑了几句，随即又晕了过去。\n",
      "迷迷糊糊之中，但觉胸口烦恶，全身气血倒转，说不出的难受，过了良久，神智渐复，\n"
     ]
    }
   ],
   "source": [
    "chunk_len = 300\n",
    "\n",
    "def random_chunk(chunk_len = 100):\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def char2tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = vocab_to_int[string[c]]\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, model=\"gru\",n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.model = model\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        if self.model == \"gru\":\n",
    "            self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        elif self.model == \"lstm\":\n",
    "            self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        batch_size = input.size(0)\n",
    "        encoded = self.encoder(input)\n",
    "        output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
    "        output = self.decoder(output.view(batch_size, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self,batch_size):\n",
    "        if self.model == \"lstm\":\n",
    "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)),\n",
    "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)))\n",
    "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set(chunk_len,batch_size):    \n",
    "    inp = torch.LongTensor(batch_size, chunk_len)\n",
    "    target = torch.LongTensor(batch_size, chunk_len)\n",
    "    for i in range(batch_size):\n",
    "        chunk = random_chunk(chunk_len)\n",
    "        inp[i] = char2tensor(chunk[:-1])\n",
    "        target[i] = char2tensor(chunk[1:])\n",
    "    if use_gpu:\n",
    "        inp = inp.cuda()\n",
    "        target = target.cuda()\n",
    "    else:\n",
    "        inp = Variable(inp)\n",
    "        target = Variable(target)\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(decoder, prime_str='A', predict_len=100, temperature=0.8, use_gpu = False):\n",
    "    hidden = decoder.init_hidden(1)\n",
    "    prime_input = char2tensor(prime_str).unsqueeze(0)\n",
    "    \n",
    "    if use_gpu:\n",
    "        if isinstance(hidden, tuple):\n",
    "            hidden = (hidden[0].cuda(), hidden[1].cuda())\n",
    "        else:\n",
    "            hidden = hidden.cuda()\n",
    "        prime_input = prime_input.cuda()\n",
    "    \n",
    "    predicted = prime_str\n",
    "    \n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[:,p], hidden)\n",
    "    \n",
    "    inp = prime_input[:,-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        i = top_i.data[0].item()\n",
    "        #print (i)\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = int_to_vocab[i]\n",
    "        predicted += predicted_char\n",
    "        inp = char2tensor(predicted_char).unsqueeze(0)\n",
    "        if use_gpu:\n",
    "            inp = inp.cuda()\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(inp,target,batch_size):\n",
    "    hidden = decoder.init_hidden(batch_size)\n",
    "    if use_gpu:\n",
    "        inp = inp.cuda()\n",
    "        if isinstance(hidden, tuple):\n",
    "            hidden = (hidden[0].cuda(), hidden[1].cuda())\n",
    "        else:\n",
    "            hidden = hidden.cuda()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[:,c], hidden)\n",
    "        loss += criterion(output.view(batch_size, -1), target[:,c])\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / chunk_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 5000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 512\n",
    "n_layers = 2\n",
    "lr = 0.005\n",
    "batch_size = 5\n",
    "chunk_len = 50\n",
    "\n",
    "decoder = RNN(n_characters, hidden_size, n_characters,\"lstm\", n_layers)\n",
    "if use_gpu:\n",
    "    decoder.cuda()\n",
    "\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(*random_training_set(chunk_len,batch_size),batch_size)       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[(%d %d%%) %.4f]' % ( epoch, epoch / n_epochs * 100, loss))\n",
    "        print(evaluate(decoder,'令', 50, use_gpu=use_gpu), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:18: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100 2%) 3.5636]\n",
      "令狐冲缩身乱快。”\n",
      "上官云道：“他好啦，咱们是在大奘中的剑谱，岂肯偷偷，反而是名门正派的，倒是要先说。 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:29: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(200 4%) 3.9995]\n",
      "令狐冲忙在这等交情，嘴角双熊，渔开包袱，才见了一个女子，显是几个笑话。\n",
      "任我行不等一定要持剑招，没想起 \n",
      "\n",
      "[(300 6%) 3.7245]\n",
      "令狐冲瞧瞧上去，不将他们二人？”盈盈道：“是。”\n",
      "林震南道：“到来，万里一处伤，你才是……我本来不知的 \n",
      "\n",
      "[(400 8%) 3.7003]\n",
      "令狐冲，在这位嵩山派中诸人的埋伏之下，早已得罪。”令狐冲道：“怎么？”这次是谁都不住令狐冲之中，十六坛 \n",
      "\n",
      "[(500 10%) 3.4611]\n",
      "令狐冲的手握定闲、定逸师太、定逸师太、定逸师太、定逸、定逸师太、定逸师娘这等的大家叫做不可，却不敢。” \n",
      "\n",
      "[(600 12%) 3.9048]\n",
      "令狐冲和盈盈擒住。令狐冲笑道：“他们从来拉不住，不过你为徒弟子们身旁，该灵这才仰人，便要我们五岳剑派之 \n",
      "\n",
      "[(700 14%) 3.6245]\n",
      "令狐冲转了个弯子的滑路，全然而视，到盈盈已然而进，便是恒山派历人不及。盈盈虽然分明，脸上还是尴尬，似乎 \n",
      "\n",
      "[(800 16%) 3.7487]\n",
      "令狐冲的解药。\n",
      "令狐冲道：“是啊，那是用手，深来心中想到这名汉子，做事可从外河湖上。”\n",
      "令狐冲心想：“ \n",
      "\n",
      "[(900 18%) 3.7456]\n",
      "令狐冲，惊魂欣慰，大声道：“我……我……”\n",
      "令狐冲心道：“令狐贤侄，我们改得一路无辜，可是咱们都是甚么 \n",
      "\n",
      "[(1000 20%) 3.3427]\n",
      "令狐冲一呆：“听说这个给小师妹说的？”那人道：“是！”令狐冲道：“甚么可不会真气？”\n",
      "盈盈道：“当然是 \n",
      "\n",
      "[(1100 22%) 3.8609]\n",
      "令狐冲见到了一阵浮惭之中，都没见到练黑白子，跟着刃牢管牙，跟着坐骑，将拳脚的分别将一盏油灯打断，一声长 \n",
      "\n",
      "[(1200 24%) 3.6258]\n",
      "令狐冲道：“你奶奶的，师父，你的性命太过极大，特地好好俊。”\n",
      "令狐冲道：“好罢！”又想：“那也不妨。” \n",
      "\n",
      "[(1300 26%) 3.8002]\n",
      "令狐冲道：“阁下你们两位教主活情，晚辈也有不顾，说不定是死身的，倒也无法可憎。”他知道他们又向主响上， \n",
      "\n",
      "[(1400 28%) 3.6366]\n",
      "令狐冲当然不可，一招之间，陪着令狐冲转过身来，一怔，笑道：“这长脚成名，是真的。”\n",
      "令狐冲点头道：“刚 \n",
      "\n",
      "[(1500 30%) 3.6996]\n",
      "令狐冲脸上鼓声，这才离开椅派人物，当能热闹已加入发梦，只笑了一会，说道：“谢开门人，是门门了他，是谁要 \n",
      "\n",
      "[(1600 32%) 3.7335]\n",
      "令狐冲心中怦怦乱跳，双眼里走了一句：“我爹爹教教主田伯光这话不骗我们再习这套剑法，令狐冲每一个是天香断 \n",
      "\n",
      "[(1700 34%) 2.9159]\n",
      "令狐冲心想：“魔教任小姐的武功如此奇妙，但不知是实不能说。”\n",
      "众人俊脸通红，神情不实，突然向后跃起，刷 \n",
      "\n",
      "[(1800 36%) 3.3858]\n",
      "令狐冲目光中带水，别说到了这句话，确然无理不容。\n",
      "刘正风凝视着自己这么大面，那便如何？”\n",
      "何三七 ，心 \n",
      "\n",
      "[(1900 38%) 3.4923]\n",
      "令狐冲罩过了头，心下暗暗好笑，没会落地，遇上了几个人，只想向大哥面前辈的所居，但听得爹爹了不起来。\n",
      "他 \n",
      "\n",
      "[(2000 40%) 3.5340]\n",
      "令狐冲心下不安，但觉得铮一般，另有一人四人搂架不住，登时轰然大荡。令狐冲心想：“这六个怪人武功高强，却 \n",
      "\n",
      "[(2100 42%) 3.1408]\n",
      "令狐冲、余沧海等等三人齐声，心想：“少林派是五仙教主，可是非于一天一大坛舞之意。”曲非烟冷笑道：“你二 \n",
      "\n",
      "[(2200 44%) 3.2954]\n",
      "令狐冲换剑，瞧来到此处，便已便和华山派送命。在下与令狐冲和这两个多月省做人。\n",
      "岳不群却是候圣教主，属下 \n",
      "\n",
      "[(2300 46%) 4.0278]\n",
      "令狐冲素来叮嘱位禅师叫他的声音，心中感激，忍不住皮声道：“我不小心，重伤你，我便然再来找你。’令狐大哥 \n",
      "\n",
      "[(2400 48%) 3.6244]\n",
      "令狐冲一呆，蓦地里想起：“最好的本事，是说要我们说甚么？”桃枝仙道：“我猜想，这是个……”张夫人道：“ \n",
      "\n",
      "[(2500 50%) 3.6121]\n",
      "令狐冲大吃一惊，道：“我知道你也是想，便不用说甚么不做好朋友，伸手便要拿他们来。近年前面如身边勾结，事 \n",
      "\n",
      "[(2600 52%) 3.8112]\n",
      "令狐大哥。倘若他师父将那边得稀烂，只是岳灵珊的心事。不过……也要救我的，我没有丝毫无恶，不免么剑招也是 \n",
      "\n",
      "[(2700 54%) 3.5907]\n",
      "令狐冲。\n",
      "令狐冲道：“原来尚有的也罢了。”\n",
      "令狐冲从音律取出一块大石旁，一言自语：“你慢慢走向我退开罢 \n",
      "\n",
      "[(2800 56%) 3.4957]\n",
      "令狐冲要害死战，准了他们手臂便跟了他们，不禁紧了，无法门户，大声喝道：“站了起来，一个人他十个人最美的 \n",
      "\n",
      "[(2900 57%) 3.2260]\n",
      "令狐冲突觉一声，递过去。他心中总是生悯。\n",
      "岳夫人已好过了二十余种铁和，说不定便是镖局。\n",
      "令狐冲心道：“ \n",
      "\n",
      "[(3000 60%) 3.3916]\n",
      "令狐冲一扇门客气去，只听见恒山派众弟子身子一晃，拍的一声响，飞过去罢。\n",
      "那汉子道：“呸！”\n",
      "这番不是一 \n",
      "\n",
      "[(3100 62%) 3.0596]\n",
      "令狐冲一剑将长剑，重身原已是不向她剑法，左脚踹自是强弱，剑锋如鬼，分别快说这话，岂不是给他解敌？\n",
      "岳不 \n",
      "\n",
      "[(3200 64%) 3.3880]\n",
      "令狐冲叫道：“你……你……你……你不是……”仪琳道：“这是说，我先使她们来。”桃干仙道：“不错，好像他 \n",
      "\n",
      "[(3300 66%) 3.3615]\n",
      "令狐冲心下一凛，又叫了一声。\n",
      "众人伸手双臂在他手中，心下无一十分喜悦。\n",
      "令狐冲心想：“我让她为师，虽然 \n",
      "\n",
      "[(3400 68%) 3.6679]\n",
      "令狐冲，大师哥，从来不过华山派的掌门。”岳不群道：“那……那还有甚么好？”林平之越听越听越听越过数百年 \n",
      "\n",
      "[(3500 70%) 3.6239]\n",
      "令狐冲倚在最上，一字大路尚未止歇，但说话声音，低声道：“我……我……”那婆婆道：“师太！”长剑一挥，岳 \n",
      "\n",
      "[(3600 72%) 3.6092]\n",
      "令狐冲急前的血腥紧紧，说道：“不知第一件事，他手里便将罪了我们的。”这时，地不下山时，便现身有时，一人 \n",
      "\n",
      "[(3700 74%) 3.2124]\n",
      "令狐冲大喝。令狐冲骇然在自己身上，虽然也有一件青色。\n",
      "令狐冲道：“弟子无礼，此事不过是个厉害。”\n",
      "令狐 \n",
      "\n",
      "[(3800 76%) 3.5243]\n",
      "令狐冲一笑，说道：“不过用师，比剑夺帅，可别以为师姊，连……那太你……”\n",
      "岳不群情知他一阵剧斗。天门道 \n",
      "\n",
      "[(3900 78%) 3.1600]\n",
      "令狐冲，说道：“我并没说话，你跟我说到，不知道我好，咱们今晚后令狐大哥还在也不会再说。”\n",
      "林平之道：“ \n",
      "\n",
      "[(4000 80%) 3.6159]\n",
      "令狐冲认输，又有谁敢去瞧瞧六只老鼠？”说着一拱手，说道：“我虽然都十分血明，否则青城派的好手，只有我令 \n",
      "\n",
      "[(4100 82%) 3.4421]\n",
      "令狐掌门，好像是嵩山派的所在独孤九剑之间，群豪如此无奈，这会使这么招架啊。”\n",
      "令狐冲心下明白：“不然是 \n",
      "\n",
      "[(4200 84%) 3.2407]\n",
      "令狐冲目步踏开，大显子边道：“这个……这个时候却又打败，只怕坏人立时齐上下山。咱们手中人，你们上峰来干 \n",
      "\n",
      "[(4300 86%) 3.3655]\n",
      "令狐冲到了少林派僧人。群雄一时杀了少林，这一招“苍松迎客”，这时尖锐，四下皆受的石板上刺了几个弯，右手 \n",
      "\n",
      "[(4400 88%) 3.1106]\n",
      "令狐冲来回着，心中一震：“任教主：于酒来对付魔教，你自己认了这个人，只道那老实学了这等三是山壁。先来风 \n",
      "\n",
      "[(4500 90%) 3.8862]\n",
      "令狐冲寻思：“我说了这些话，也可不能。”\n",
      "随即突然打开的脚步，道：“魔教任施主终于熟悉。”曲非烟哼了一 \n",
      "\n",
      "[(4600 92%) 3.2482]\n",
      "令狐冲心下惊疑，似是奋妙派几个人来。岂知此刻也有了方证大师、少林派的四十多名弟子武功了得。在饭两大门外 \n",
      "\n",
      "[(4700 94%) 3.6901]\n",
      "令狐冲千万不可遏步，只见东首门板。\n",
      "岳不群道：“都是撞死了。”\n",
      "林平之道：“你嫁活了罢，我还叫他的贼子 \n",
      "\n",
      "[(4800 96%) 3.1874]\n",
      "令者应道：“令狐公子，你师父为人不胜，但听得这许多头子汉大丈夫，这才济济，这自然没提了去，小师妹在外人 \n",
      "\n",
      "[(4900 98%) 2.8943]\n",
      "令狐公子。”\n",
      "令狐冲恍然大悟：“有甚么办？”\n",
      "令狐冲道：“先前人都知寒宝分舌的教主。你师父、师娘一生之 \n",
      "\n",
      "[(5000 100%) 3.3336]\n",
      "令狐冲在二人相聚并，不是白色的病望，林平之身内向天停住，令狐冲微微一笑，道：“这位岳姑娘，你放心我情的 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Continue Training\n",
    "\n",
    "n_epochs = 5000\n",
    "print_every = 100\n",
    "chunk_len = 100\n",
    "batch_size = 50\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(*random_training_set(chunk_len,batch_size),batch_size)       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[(%d %d%%) %.4f]' % ( epoch, epoch / n_epochs * 100, loss))\n",
    "        print(evaluate(decoder,'令', 50, use_gpu=use_gpu), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save Model for Training next time\n",
    "torch.save(decoder.state_dict(), 'model.pt')\n",
    "\n",
    "import pickle\n",
    "with open('vocab_to_int.pickle', 'wb') as handle:\n",
    "    pickle.dump(vocab_to_int, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('int_to_vocab.pickle', 'wb') as handle:\n",
    "    pickle.dump(int_to_vocab, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
