{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Char-rnn 笑傲江湖 - Continue training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f= 'data/xiaoaojianghu_jinyong.txt'\n",
    "file = open(f, encoding='utf-16').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file_len = len(file)\n",
    "n_characters = len(set(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_lookup_tables(file):\n",
    "    vocab = set(file)\n",
    "    vocab_to_int = {word: idx for idx, word in enumerate(vocab)}\n",
    "    int_to_vocab = dict(enumerate(vocab))\n",
    "    return vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#vocab_to_int, int_to_vocab = create_lookup_tables(file)\n",
    "import pickle\n",
    "with open('vocab_to_int.pickle', 'rb') as handle:\n",
    "    vocab_to_int = pickle.load(handle)\n",
    "    \n",
    "with open('int_to_vocab.pickle', 'rb') as handle:\n",
    "    int_to_vocab = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "教的只是剑法，但于他议论风范，不但钦仰敬佩，更是觉得亲近之极，说不出的投机。风清扬是高了他两辈的太师叔，可是令狐冲内心，却隐隐然有一股平辈知己、相见恨晚的交谊，比之恩师岳不群，似乎反而亲切得多，心想：“\n"
     ]
    }
   ],
   "source": [
    "chunk_len = 300\n",
    "\n",
    "def random_chunk(chunk_len = 100):\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def char2tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = vocab_to_int[string[c]]\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, model=\"gru\",n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.model = model\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        if self.model == \"gru\":\n",
    "            self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        elif self.model == \"lstm\":\n",
    "            self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        batch_size = input.size(0)\n",
    "        encoded = self.encoder(input)\n",
    "        output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
    "        output = self.decoder(output.view(batch_size, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self,batch_size):\n",
    "        if self.model == \"lstm\":\n",
    "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)),\n",
    "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)))\n",
    "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def random_training_set(chunk_len,batch_size):    \n",
    "    inp = torch.LongTensor(batch_size, chunk_len)\n",
    "    target = torch.LongTensor(batch_size, chunk_len)\n",
    "    for i in range(batch_size):\n",
    "        chunk = random_chunk(chunk_len)\n",
    "        inp[i] = char2tensor(chunk[:-1])\n",
    "        target[i] = char2tensor(chunk[1:])\n",
    "    if use_gpu:\n",
    "        inp = inp.cuda()\n",
    "        target = target.cuda()\n",
    "    else:\n",
    "        inp = Variable(inp)\n",
    "        target = Variable(target)\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def evaluate(decoder, prime_str='A', predict_len=100, temperature=0.8, use_gpu = False):\n",
    "    hidden = decoder.init_hidden(1)\n",
    "    prime_input = char2tensor(prime_str).unsqueeze(0)\n",
    "    \n",
    "    if use_gpu:\n",
    "        if isinstance(hidden, tuple):\n",
    "            hidden = (hidden[0].cuda(), hidden[1].cuda())\n",
    "        else:\n",
    "            hidden = hidden.cuda()\n",
    "        prime_input = prime_input.cuda()\n",
    "    \n",
    "    predicted = prime_str\n",
    "    \n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[:,p], hidden)\n",
    "    \n",
    "    inp = prime_input[:,-1]\n",
    "    if use_gpu:\n",
    "        inp = inp.cuda()\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)      \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        i = top_i.data[0].item()\n",
    "        #print (i)\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = int_to_vocab[i]\n",
    "        predicted += predicted_char\n",
    "        inp = char2tensor(predicted_char).unsqueeze(0)\n",
    "        if use_gpu:\n",
    "            inp = inp.cuda()\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train(inp,target,batch_size):\n",
    "    hidden = decoder.init_hidden(batch_size)\n",
    "    if use_gpu:\n",
    "        inp = inp.cuda()\n",
    "        if isinstance(hidden, tuple):\n",
    "            hidden = (hidden[0].cuda(), hidden[1].cuda())\n",
    "        else:\n",
    "            hidden = hidden.cuda()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[:,c], hidden)\n",
    "        loss += criterion(output.view(batch_size, -1), target[:,c])\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / chunk_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model From Previous Training and continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:18: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(200 4%) 1.6212]\n",
      "令狐冲心想：“我几时得罪了你，有个人，便练了几年，众位婆婆但先前家定逸师太一番新水，入伏圣姑。两位明鉴 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:29: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5000\n",
    "print_every = 200\n",
    "plot_every = 50\n",
    "hidden_size = 512\n",
    "n_layers = 2\n",
    "lr = 0.005\n",
    "chunk_len = 100\n",
    "batch_size = 50\n",
    "\n",
    "\n",
    "decoder = RNN(n_characters, hidden_size, n_characters,\"lstm\", n_layers)\n",
    "if use_gpu:\n",
    "    decoder.cuda()\n",
    "decoder.load_state_dict(torch.load('model.pt'))\n",
    "decoder.train()\n",
    "\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(*random_training_set(chunk_len,batch_size),batch_size)       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[(%d %d%%) %.4f]' % ( epoch, epoch / n_epochs * 100, loss))\n",
    "        print(evaluate(decoder,'令', 50, use_gpu=use_gpu), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:18: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(200 4%) 1.8789]\n",
      "令狐冲迷迷糊糊的仙咬住了他，令狐冲双目向岭跌出来，说道：“你身子横斩，吓他一个道理。”\n",
      "令狐冲道：“我 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:29: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(400 8%) 1.7620]\n",
      "令狐冲道：“方师哥，令狐兄，请你将他补上了。”\n",
      "突见那时汉子叫道：“且慢。”令狐冲心中一阵凄凉，对这婆 \n",
      "\n",
      "[(600 12%) 1.7325]\n",
      "令狐冲心中一喜，忙道：“既然不是寻常各派的少年，这是田某五毒教七个方位相授，命小师妹不利于我，那不必用 \n",
      "\n",
      "[(800 16%) 1.8344]\n",
      "令狐冲笑道：“令狐冲，你对我这位丁兄包含了你们吗？”老公公道：“为何？”身子一晃，右足一抓，长剑一骨， \n",
      "\n",
      "[(1000 20%) 1.7577]\n",
      "令狐冲大笑，都道：“左掌门是由于徒成不入，咱们便随也没有，但如今晚，也都是乐厚的贵教，我和曲大哥多谢你 \n",
      "\n",
      "[(1200 24%) 1.7336]\n",
      "令狐冲笑道：“方证大师是衡山派的，前来生火入怀。”令狐冲道：“人家此番有伤，我总是不明不白。刚才你快活 \n",
      "\n",
      "[(1400 28%) 1.7865]\n",
      "令狐冲不由得心动，摸不到余人，但片刻间有新之意，心想已是颇觉不合，便以此刻细看，但她竟始终住不清楚，正 \n",
      "\n",
      "[(1600 32%) 1.7221]\n",
      "令狐冲道：“你认得我是偷听我的传人，但从来就没放过，咱们一起死了好一会，忽然脸上阴晴不定。\n",
      "令狐冲听了 \n",
      "\n",
      "[(1800 36%) 1.8146]\n",
      "令狐冲道：“小师妹，令狐冲，你死了。”将那碗馄饨的模字也不大起议。\n",
      "田伯光又道：“那自然不会怪你的。我 \n",
      "\n",
      "[(2000 40%) 1.6951]\n",
      "令狐冲一个自出。”那婆婆道：“正是。”一伸手，从怀中取出一个瓷瓶，轿子后上雪了点头，默然不语，心下均有 \n",
      "\n",
      "[(2200 44%) 1.6148]\n",
      "令狐冲上了去，令狐冲长剑一开，将玉米棒喝震死了。\n",
      "令狐冲大惊，叫道：“师娘！”探她头上一把，轻声道：“ \n",
      "\n",
      "[(2400 48%) 1.7704]\n",
      "令狐冲对自己颇有疑忌之意。\n",
      "仪清道：“如果你我份量不休，担心便是。”\n",
      "令狐冲道：“你……你别怕！”\n",
      "令 \n",
      "\n",
      "[(2600 52%) 1.7953]\n",
      "令狐冲道：“定闲、定逸两位师伯，是华山派掌门岳先生门下，剑术之精，难以自制，和你们一齐冲上了一个半，无 \n",
      "\n",
      "[(2800 56%) 1.7054]\n",
      "令狐冲又觉不答，心中却是一觉念头，听他说笑话也是在骂她。令狐冲叫道：“你真的死样？”令狐冲叹了口气，说 \n",
      "\n",
      "[(3000 60%) 1.6441]\n",
      "令狐冲脸上一阵冰冷。那姓谭的道：“六……小……小……小师父，那还……”蓝凤凰笑道：“又没改过？”\n",
      "林平 \n",
      "\n",
      "[(3200 64%) 1.6858]\n",
      "令狐冲道：“不错，我不要见你。你想，我难道还是要你冒雨胡诌，不是令狐冲。”桃干仙道：“你做，别说是我？ \n",
      "\n",
      "[(3400 68%) 1.6898]\n",
      "令狐冲道：“晚辈令狐冲，是前辈所传的内功前辈，更不能将他们让位出来？”\n",
      "令狐冲道：“弟子见了我答应，岳 \n",
      "\n",
      "[(3600 72%) 1.6380]\n",
      "令狐冲心下一片混乱，心下甚是惴惴，寻些便给她害死了，又一死而为的美女，哪知又在三位师姊所杀的浩劫原无《 \n",
      "\n",
      "[(3800 76%) 1.6776]\n",
      "令狐冲向北望去，眼光中充满了愤怒之意。\n",
      "任我行笑道：“啊，你不客气？”大叫一声，奔近成西。盈盈果然不听 \n",
      "\n",
      "[(4000 80%) 1.6663]\n",
      "令狐冲道：“你们是嵩山派岳不群岳家大局，这句话如果有些字。”\n",
      "岳不群重纵武功一道，风清扬是否能认出我们 \n",
      "\n",
      "[(4200 84%) 1.7713]\n",
      "令狐老弟兄弟当真不识老成了。”向问天道：“大英雄要请两位其中。”说着双手叫道：“啊哟，你们身上好热，再 \n",
      "\n",
      "[(4400 88%) 1.6446]\n",
      "令狐冲缩回左胁，难以脱手，断去足底，左手在费彬一击中了咬鞭，递到了全是缓缓补脚，殿口点着一只乌龟，足见 \n",
      "\n",
      "[(4600 92%) 1.6765]\n",
      "令狐冲身在厅安停住。\n",
      "盈盈知他已闪身挡格，有的随即反手便风清扬腰间的额头汗湿，令狐冲不禁掉泪，过了一会 \n",
      "\n",
      "[(4800 96%) 1.7321]\n",
      "令狐冲和盈盈满脸都被人绑缚，又何尝不为奇，说道：“我日月神教的药酒，学过武林中的和气。”\n",
      "令狐冲腰间拔 \n",
      "\n",
      "[(5000 100%) 1.6805]\n",
      "令狐冲提起箫来。\n",
      "盈盈的本色陡地站起，和方丈两意，一时之间，藏身一炸，那军官险些葬身下台，大叫仪琳的呼 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(*random_training_set(chunk_len,batch_size),batch_size)       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[(%d %d%%) %.4f]' % ( epoch, epoch / n_epochs * 100, loss))\n",
    "        print(evaluate(decoder,'令', 50, use_gpu=use_gpu), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(decoder.state_dict(), 'model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
