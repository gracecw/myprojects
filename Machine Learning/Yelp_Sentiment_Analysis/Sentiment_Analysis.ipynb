{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-13-196.us-west-2.compute.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.ml import Pipeline, PipelineModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\",\"mongodb://ec2-34-212-28-18.us-west-2.compute.amazonaws.com/msan697.review\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+----------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|                 _id|         business_id|cool|      date|funny|           review_id|stars|                text|useful|             user_id|\n",
      "+--------------------+--------------------+----+----------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|[5a5d41a969b675a5...|uYHaNptLzDLoV_JZ_...|   0|2016-07-12|    0|VfBHSwC5Vz_pbFluy...|    5|My girlfriend and...|     0|cjpdDjZyprfyDG3Rl...|\n",
      "+--------------------+--------------------+----+----------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_data.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check distribution of the rating star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|stars|  count|\n",
      "+-----+-------+\n",
      "|    1| 639849|\n",
      "|    3| 570819|\n",
      "|    5|1988003|\n",
      "|    4|1135830|\n",
      "|    2| 402396|\n",
      "+-----+-------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print review_data.groupBy(review_data[\"stars\"]).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclude neutral review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_neg(star):\n",
    "    if star <3:\n",
    "        return int(0) #negative\n",
    "    elif star >3 :\n",
    "        return int(1) #positive\n",
    "    else:\n",
    "        return int(2) #neutral\n",
    "    \n",
    "star_to_senti = udf(lambda x:pos_neg(x))\n",
    "train_test_DF_raw = review_data.select('text',star_to_senti('stars').alias('label')).filter(\"label != 2\") #exclude neutral reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "train_test_DF = train_test_DF_raw.withColumn(\"label\", train_test_DF_raw[\"label\"].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|label|  count|\n",
      "+-----+-------+\n",
      "|  0.0|1042245|\n",
      "|  1.0|3123833|\n",
      "+-----+-------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print train_test_DF.groupBy(train_test_DF[\"label\"]).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|My girlfriend and...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test_DF.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TFIDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |label|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|My girlfriend and I stayed here for nights and loved it The location of this hotel and very decent price makes this an amazing deal When you walk out the front door Scott Monument and Princes street are right in front of you Edinburgh Castle and the Royal Mile is a minute walk via a close right around the corner and there are so many hidden gems nearby including Calton Hill and the newly opened Arches that made this location incredible The hotel itself was also very nice with a reasonably priced bar very considerate staff and small but comfortable rooms with excellent bathrooms and showers Only two minor complaints are no telephones in room for room service not a huge deal for us and no AC in the room but they have huge windows which can be fully opened The staff were incredible though letting us borrow umbrellas for the rain giving us maps and directions and also when we had lost our only UK adapter for charging our phones gave us a very fancy one for free I would highly recommend this hotel to friends and when I return to Edinburgh which I most definitely will I will be staying here without any hesitation|1.0  |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#remove punctuation\n",
    "import re\n",
    "import string\n",
    "\n",
    "def remove_num_punct(text):\n",
    "\n",
    "    my_string = text.replace(\"-\", \" \")\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", my_string)  # delete stuff but leave at least a space to avoid clumping together\n",
    "\n",
    "    nopunct = nopunct.split()\n",
    "    #nopunct = [stemmer.stem(w).strip(\" \") for w in nopunct] #remove stop word and normalize word using stemmer.\n",
    "    nopunct = [w.strip() for w in nopunct]\n",
    "    nopunct = ' '.join(nopunct)\n",
    "    \n",
    "    return nopunct\n",
    "\n",
    "udf_num_punct = udf(lambda x:remove_num_punct(x))\n",
    "review_rmsw = train_test_DF.select(udf_num_punct('text').alias('text'), 'label')\n",
    "review_rmsw.show(1,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### setNumFeatures(20)\n",
    "n_features = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer().setInputCol(\"text\").setOutputCol(\"words\")\n",
    "remover= StopWordsRemover().setInputCol(\"words\").setOutputCol(\"filtered\").setCaseSensitive(False)\n",
    "hashingTF = HashingTF().setNumFeatures(n_features).setInputCol(\"filtered\").setOutputCol(\"rawFeatures\")\n",
    "idf = IDF().setInputCol(\"rawFeatures\").setOutputCol(\"features\").setMinDocFreq(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set= review_rmsw.randomSplit([0.8, 0.2])\n",
    "train_set = train_set.cache()\n",
    "test_set = test_set.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy on the test set \n",
    "def evaluate_metric(predictions):\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator().setMetricName(\"areaUnderROC\")\n",
    "    print \"Area under ROC curve:\",evaluator.evaluate(predictions)\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                                  metricName=\"f1\")\n",
    "    f1 = evaluator.evaluate(predictions)\n",
    "    print(\"F1_score = %0.4f\" %(f1))\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                                  metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(\"Accuracy = %0.4f\" %(accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve: 0.907917008938\n",
      "F1_score = 0.8302\n",
      "Accuracy = 0.8469\n",
      "CPU times: user 740 ms, sys: 564 ms, total: 1.3 s\n",
      "Wall time: 9min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr =  LogisticRegression(maxIter=100, regParam=0.01, elasticNetParam=0.8)\n",
    "pipeline=Pipeline(stages=[tokenizer,remover,hashingTF,idf, lr])\n",
    "logreg_model=pipeline.fit(train_set)\n",
    "predictions = logreg_model.transform(test_set)\n",
    "#print evaluation metrics\n",
    "evaluate_metric(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                text|label|               words|            filtered|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|A Double Double w...|  1.0|[a, double, doubl...|[double, double, ...|(1000,[100,319,48...|(1000,[100,319,48...|[-1.5297907896663...|[0.17802429781682...|       1.0|\n",
      "|A brewery less th...|  1.0|[a, brewery, less...|[brewery, less, m...|(1000,[44,77,86,1...|(1000,[44,77,86,1...|[-1.7915189922039...|[0.14288659155240...|       1.0|\n",
      "|A calmer shopping...|  1.0|[a, calmer, shopp...|[calmer, shopping...|(1000,[19,43,144,...|(1000,[19,43,144,...|[-2.0676370296022...|[0.11228235199596...|       1.0|\n",
      "|A diamond in the ...|  1.0|[a, diamond, in, ...|[diamond, rough, ...|(1000,[98,105,300...|(1000,[98,105,300...|[-1.1405260447832...|[0.24222379163323...|       1.0|\n",
      "|A nice place to t...|  1.0|[a, nice, place, ...|[nice, place, tak...|(1000,[99,115,160...|(1000,[99,115,160...|[-1.9463311716895...|[0.12495395791934...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Unigram Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve: 0.61095343296\n",
      "F1_score = 0.8502\n",
      "Accuracy = 0.8479\n",
      "CPU times: user 172 ms, sys: 88 ms, total: 260 ms\n",
      "Wall time: 4min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb = NaiveBayes(smoothing = 1.0, modelType = \"multinomial\")\n",
    "pipeline=Pipeline(stages=[tokenizer,remover,hashingTF,idf, nb])\n",
    "nb_model=pipeline.fit(train_set)\n",
    "nb_prediction = nb_model.transform(test_set)\n",
    "#print evaluation metrics\n",
    "evaluate_metric(nb_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                text|label|               words|            filtered|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|A Double Double w...|  1.0|[a, double, doubl...|[double, double, ...|(1000,[100,319,48...|(1000,[100,319,48...|[-157.89033961127...|[0.00348594762034...|       1.0|\n",
      "|A brewery less th...|  1.0|[a, brewery, less...|[brewery, less, m...|(1000,[44,77,86,1...|(1000,[44,77,86,1...|[-608.36092788982...|[0.00133602632901...|       1.0|\n",
      "|A calmer shopping...|  1.0|[a, calmer, shopp...|[calmer, shopping...|(1000,[19,43,144,...|(1000,[19,43,144,...|[-879.08842241835...|[3.90940210326704...|       1.0|\n",
      "|A diamond in the ...|  1.0|[a, diamond, in, ...|[diamond, rough, ...|(1000,[98,105,300...|(1000,[98,105,300...|[-258.54027602906...|[1.61176967055486...|       1.0|\n",
      "|A nice place to t...|  1.0|[a, nice, place, ...|[nice, place, tak...|(1000,[99,115,160...|(1000,[99,115,160...|[-1067.4824017218...|[5.03200114126107...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_prediction.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Bigram Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigram tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = Tokenizer().setInputCol(\"text\").setOutputCol(\"words\")\n",
    "#remover= StopWordsRemover().setInputCol(\"words\").setOutputCol(\"filtered\").setCaseSensitive(False)\n",
    "bigram = NGram(n=2, inputCol=\"filtered\", outputCol=\"bigrams\")\n",
    "hashingTF_bigram = HashingTF().setNumFeatures(n_features).setInputCol(\"bigrams\").setOutputCol(\"rawFeatures\")\n",
    "idf_bigram = IDF().setInputCol(\"rawFeatures\").setOutputCol(\"features\").setMinDocFreq(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve: 0.604550332169\n",
      "F1_score = 0.7338\n",
      "Accuracy = 0.7372\n",
      "CPU times: user 172 ms, sys: 108 ms, total: 280 ms\n",
      "Wall time: 7min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb = NaiveBayes(smoothing = 1.0, modelType = \"multinomial\")\n",
    "pipeline=Pipeline(stages=[tokenizer,remover,bigram,hashingTF_bigram,idf_bigram, nb])\n",
    "nb_model_bigram=pipeline.fit(train_set)\n",
    "nb_prediction_bigram = nb_model_bigram.transform(test_set)\n",
    "\n",
    "#print evaluation metrics\n",
    "evaluate_metric(nb_prediction_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                text|label|               words|            filtered|             bigrams|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|A Double Double w...|  1.0|[a, double, doubl...|[double, double, ...|[double double, d...|(1000,[37,120,197...|(1000,[37,120,197...|[-146.41508108231...|[0.26315132445657...|       1.0|\n",
      "|A brewery less th...|  1.0|[a, brewery, less...|[brewery, less, m...|[brewery less, le...|(1000,[13,64,95,1...|(1000,[13,64,95,1...|[-728.87324722138...|[0.00396590705037...|       1.0|\n",
      "|A calmer shopping...|  1.0|[a, calmer, shopp...|[calmer, shopping...|[calmer shopping,...|(1000,[2,14,47,49...|(1000,[2,14,47,49...|[-758.85555044600...|[0.18586546429835...|       1.0|\n",
      "|A diamond in the ...|  1.0|[a, diamond, in, ...|[diamond, rough, ...|[diamond rough, r...|(1000,[225,237,29...|(1000,[225,237,29...|[-228.13694876473...|[0.52075624639486...|       0.0|\n",
      "|A nice place to t...|  1.0|[a, nice, place, ...|[nice, place, tak...|[nice place, plac...|(1000,[14,20,23,3...|(1000,[14,20,23,3...|[-1045.5799264891...|[0.21218153636662...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_prediction_bigram.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Trigram Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tribgram tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = Tokenizer().setInputCol(\"text\").setOutputCol(\"words\")\n",
    "#remover= StopWordsRemover().setInputCol(\"words\").setOutputCol(\"filtered\").setCaseSensitive(False)\n",
    "trigram = NGram(n=3, inputCol=\"filtered\", outputCol=\"trigrams\")\n",
    "hashingTF_trigram = HashingTF().setNumFeatures(n_features).setInputCol(\"trigrams\").setOutputCol(\"rawFeatures\")\n",
    "idf_trigram = IDF().setInputCol(\"rawFeatures\").setOutputCol(\"features\").setMinDocFreq(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve: 0.604550332169\n",
      "F1_score = 0.7338\n",
      "Accuracy = 0.7372\n",
      "CPU times: user 152 ms, sys: 116 ms, total: 268 ms\n",
      "Wall time: 5min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb = NaiveBayes(smoothing = 1.0, modelType = \"multinomial\")\n",
    "pipeline=Pipeline(stages=[tokenizer,remover,trigram,hashingTF_trigram,idf_trigram, nb])\n",
    "nb_model_trigram=pipeline.fit(train_set)\n",
    "nb_prediction_trigram = nb_model_trigram.transform(test_set)\n",
    "#print evaluation metrics\n",
    "evaluate_metric(nb_prediction_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                text|label|               words|            filtered|            trigrams|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|A Double Double w...|  1.0|[a, double, doubl...|[double, double, ...|[double double w,...|(1000,[18,134,302...|(1000,[18,134,302...|[-124.19845262747...|[0.26885139648110...|       1.0|\n",
      "|A brewery less th...|  1.0|[a, brewery, less...|[brewery, less, m...|[brewery less min...|(1000,[5,128,148,...|(1000,[5,128,148,...|[-717.29435834253...|[0.24607955873582...|       1.0|\n",
      "|A calmer shopping...|  1.0|[a, calmer, shopp...|[calmer, shopping...|[calmer shopping ...|(1000,[10,16,18,2...|(1000,[10,16,18,2...|[-739.11537546802...|[0.28590664298543...|       1.0|\n",
      "|A diamond in the ...|  1.0|[a, diamond, in, ...|[diamond, rough, ...|[diamond rough ge...|(1000,[63,266,341...|(1000,[63,266,341...|[-205.91173068438...|[0.19378420193544...|       1.0|\n",
      "|A nice place to t...|  1.0|[a, nice, place, ...|[nice, place, tak...|[nice place take,...|(1000,[9,27,60,61...|(1000,[9,27,60,61...|[-1026.2272788150...|[0.43753207279183...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_prediction_trigram.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Model 5: Multilayer perceptron classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score = 0.8901\n",
      "Accuracy = 0.8917\n",
      "-479.655319929\n"
     ]
    }
   ],
   "source": [
    "# specify layers for the neural network:\n",
    "# input layer of size 20 (features), two intermediate of size 5 and 4\n",
    "# and output of size 3 (classes)\n",
    "\n",
    "#%%time\n",
    "import time\n",
    "start =time.time()\n",
    "\n",
    "\n",
    "layers = [n_features, 5 , 2] \n",
    "# create the trainer and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=10, layers=layers, blockSize=128, seed=1234)\n",
    "pipeline=Pipeline(stages=[tokenizer,remover,hashingTF,idf, trainer])\n",
    "nn_model = pipeline.fit(train_set)\n",
    "\n",
    "nn_prediction = nn_model.transform(test_set)\n",
    "\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                                  metricName=\"f1\")\n",
    "f1 = evaluator.evaluate(nn_prediction)\n",
    "print(\"F1_score = %0.4f\" %(f1))\n",
    "    \n",
    "    \n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                                  metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(nn_prediction)\n",
    "print(\"Accuracy = %0.4f\" %(accuracy))  \n",
    "\n",
    "end = time.time()\n",
    "print (start-end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.99425533215\n"
     ]
    }
   ],
   "source": [
    "print (end-start)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                text|label|               words|            filtered|         rawFeatures|            features|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|A Double Double w...|  1.0|[a, double, doubl...|[double, double, ...|(1000,[100,319,48...|(1000,[100,319,48...|       1.0|\n",
      "|A brewery less th...|  1.0|[a, brewery, less...|[brewery, less, m...|(1000,[44,77,86,1...|(1000,[44,77,86,1...|       1.0|\n",
      "|A calmer shopping...|  1.0|[a, calmer, shopp...|[calmer, shopping...|(1000,[19,43,144,...|(1000,[19,43,144,...|       1.0|\n",
      "|A diamond in the ...|  1.0|[a, diamond, in, ...|[diamond, rough, ...|(1000,[98,105,300...|(1000,[98,105,300...|       1.0|\n",
      "|A nice place to t...|  1.0|[a, nice, place, ...|[nice, place, tak...|(1000,[99,115,160...|(1000,[99,115,160...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_prediction.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score = 0.8901\n"
     ]
    }
   ],
   "source": [
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                                  metricName=\"f1\")\n",
    "    f1 = evaluator.evaluate(nn_prediction)\n",
    "    print(\"F1_score = %0.4f\" %(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8917\n"
     ]
    }
   ],
   "source": [
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                                  metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(nn_prediction)\n",
    "    print(\"Accuracy = %0.4f\" %(accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
